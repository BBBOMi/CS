# 운영 체제

## 1. 제어 프로그램(Kernel)

* 하드웨어를 제어하는 프로그램
* 메모리, CPU, 단말기, 프린터 등 시스템의 자원 활용도를 높이기 위해 스케줄링과 자료 관리를 하는 핵심 요소이다.

## 2. 명령어 해석기(Shell)

* 사용자의 명령을 입력받아 시스템 기능을 수행하는 명령 해석기
* 사용자와 시스템 간의 인터페이스를 담당하는 프로그램이다.

## 3. 매크로

* 어셈블리어를 사용하기 쉽도록 명령어들을 문자로 치환하여 확장해 준다.

* 메크로 라이브러리는 여러 프로그램에서 공통적으로 자주 사용되는 매크로들을 모아 놓은 라이브러리다.

* 매크로는 일정의 문자열 치환과 같이 사용된 횟수만큼 명령어를 생성, 삽입하여 실행한다.

* 매크로 내에 또 다른 매크로를 정의할 수 있다.

  ### 3-1. 매크로 프로세서의 기본 기능

  1. 매크로 정의 인식 : 매크로를 정의한 부분의 시작과 종료를 파악한다.
  2. 매크로 정의 저장 : 매크로 프로세서는 매크로명과 정의된 내용을 매크로 호출시 확장하기 위해 저장한다.
  3. 매크로 호출 인식 : 매크로가 확장하기 위한 준비가 되어 있는지 확인한다.
  4. 매크로 확장 및 인수 : 매크로명이 있는 원시 프로그램 위치에 저장된 내용과 인수를 치환한다.

## 4. 로더(Loader)

* 목적 프로그램(기계어로 구성된 파일)을 실행 가능한 파일로 변환하기 위해 주기억 장소를 할당(Allocation) 하거나, 여러 개의 목적 프로그램을 연계 편집하여 CPU가 처리될 수 있는 프로그램으로 변환한다.

* 프로그램을 실행하기 위하여 프로그램을 보조 기억 장치로부터 컴퓨터의 주기억 장치에 올려 놓는 것을 좁은 의미의 로더

* 목적 프로그램들끼리 연결(Linking)시키거나 주기억 장치를 재배치(Relocation)하는 등의 포괄적인 작업을 하게 되는 것을 넓은 의미의 로더

  ### 4-1. 로더의 기능

  * 할당 -> 연결 -> 재배치 -> 적재 순으로 진행된다.

  1. 할당(Allocation) : 목적 프로그램이 실행될 주기억 장치(RAM)의 공간을 확보한다.
  2. 연결(Linking) : 여러 개의 독입적인 모듈을 연결한다.
  3. 재배치(Relocation) : 프로그램이 주기억 장치 공간 안에서 위치를 변경할 수 있게 한다.
  4. 적재(Loading) : 프로그램 전체를 주기억 장치에 한 번에 적재하게 하거나, 실행 시 필요한 일부분만을 차례로 적재하게 한다.

  ### 4-2. 로더의 종류

  1. Compile and Go 로더 : 번역 프로그램과 로더가 하나로 구성되어 번역 프로그램이 로더의 역할까지 담당하는 방식
  2. 절대 로더 : 로더의 역할이 축소되어 가장 간단한 프로그램으로 구성된 것으로 기억 장소 할당이나 연결을 프로그래머가 직접 지정하는 방식이다.
  3. 직접 연결 로더 : 로더가 할당, 연결, 재배치, 적재를 모두 수행하는 일반적인 형태이다.
  4. 기타 로더 : Binding 로더, Module 로더, 동적 적재 로더(CPU가 현재 사용중인 부분만 적재하고 미사용 중인 프로그램은 보조 기억 장치에 저장해 두는 방식, Load-On-Call)

## 5. 운영체제의 성능 평가 기준

1. 처리량(Throughput)
2. 반환 시간(Turn around Time)
3. 신뢰도(Reliablility)
4. 사용 가능도(Availability)

## 6. 디스패치(Dispatch), 스풀(Spool), 버퍼링(Buffering)

1. 디스패치
   * 준비 상태에 있는 여러 프로세스중 프로세스를 선정하여 CPU를 할당하는 시점
2. 스풀
   * 프로그램과 이를 이용하는 I/O 장치와의 속도 차를 극복하기 위한 장치로 대부분 하드 디스크가 중재한다.
3. 버퍼링
   * CPU와 입출력 장치와의 속도 차이를 줄이기 위해 메모리가 중재한다.

## 7. 인터럽트(Interrupt)

* 프로세스가 수행 중에 다른 프로세스를 수행하기 위하여 현재 수행중인 프로세스를 중단하거나 외부 입력 장치에 의해 프로세스가 중단되는 상태

* 현재 프로세스를 중단시키는 모든 행위

  ### 7-1. 인터럽트 처리 순서

  1. 인터럽트가 발생하면 운영체제가 제어권을 받는다.
  2. 운영체제는 인터럽트 받은 현태의 프로세스 상태를 저장한다.
  3. 운영체제는 인터럽트의 정보를 분석하여 지정되어 있는 루틴으로 제어권을 넘겨준다.
  4. 인터럽트 처리 루틴이 인터럽트를 처리한다.
  5. 인터럽트가 걸렸던 이전 프로세스의 상태로 복구된다.
  6. 인터럽트가 걸렸던 시점 이후부터 프로세스가 실행된다.

  ### 7-2. 인터럽트의 종류

  1. SVC(SuperVisor Call) 인터럽트
     * 운영체제의 감시 프로그래믈 호출하면 발생
     * 사용자로부터 운영체제를 보호하거나 입출력 수행 루틴 호출, 기억 장치 할당, 오퍼레이터와의 대화등을 위해 발생하는 인터럽트이다.
  2. 입출력(I/O) 인터럽트
     * 하드웨어적 인터럽트로 입출력 채널 확인, 준비, 할당, 완료 시에 발생한다.
  3. 외부(External) 인터럽트
     * 인터럽트 시계에 의해 프로세스가 시간 할당량이 종료된 경우 발생한다.
  4. 재시작(Restart) 인터럽트
     * 자용자가 재시작을 하는 경우이다.
  5. 프로그램 검사(Program Check) 인터럽트
     * Overflow, Underflow 상태시, 나눗셈에서 분모가 0인 경우
  6. 기계 검사(Hardware Check) 인터럽트
     * 시스템의 기계 고장

## 8. 문맥 교환(Context Switching)

* CPU가 할당되는 프로세스를 변경하기 위하여 현재 CPU를 사용하여 실행되고 있는 **프로세서의 상태 정보를 저장**하고 제어권을 인터럽트 서비스 루틴(ISR)에게 넘기는 작업

  ### 8-1. 문맥 교환의 위치

  1. 프로그램 실행 : 인터럽트 발생
  2. 프로그램 중단 : 현재 처리 중인 프로그램 잠시 중단
  3. 문맥 교환 : 두 개의 프로그램 정보 교환
  4. 인터럽트 처리 : 새롭게 실행된 프로그램 처리
  5. 인터럽트 서비스 루틴(ISR) : 새롭게 실행된 프로그램의 부가적인 서비스 루틴 수행
  6. 프로그램 중단 부분 재실행 : 중단되었던 기존에 프로그램 실행

  ### 8-2. 문맥 교환과 인터럽트

  * 프로세스의 중단과 실행 시 인터럽트가 발생하므로, 문맥 교환이 많이 일어난다는 것은 인터럽트가 많이 발생한다는 것이다.

  ### 8-3. 문맥 교환과 시간 할당량

  * 시간 할당량이 적어지면 : 문맥 교환 수, 인터럽트 횟수, 오버헤드가 증가하지만 여러 개의 프로세스가 동시에 수행되는 느낌을 가진다.
  * 시간 할당량이 많아지면 : 문맥 교환 수, 인터럽트 횟수, 오버헤드가 감소하지만 여러 개의 프로세스가 동시에 수행되지 못하는 느낌을 가진다.

## 9. 프로세스 제어 블록(PCB : Process Control Block)

* 운영체제 내에서 한 프로세스의 존재를 정의

* 여러개의 프로세스를 수행하는 다중 프로그래밍 환경 하에서 각 프로세스를 구분하기 위한 프로세스 정보 블록이다.

  ### 9-1. PCB 항목

  * 프로세스 식별자
  * 프로세스 현재 상태 : 준비, 실행, 대기 상태를 기억시킨다.
  * 프로그램 카운터(계수기) : 다음에 실행되는 명령어의 주소를 기억시킨다.
  * 프로세스 우선순위
  * 프로세스가 적재된 기억 장치 부분을 가리키는 포인터 : 프로세스가 시작되는 기억 장치의 시작 번지를 기억시킨다.
  * 프로세스에 할당된 자원을 가리키는 포인터 : 프로세스 처리 중에 필요한 자원의 정보를 갖고 있는 기억 장소의 시작 번지를 기억한다.
  * 처리기(CPU) 레지스터 정보
  * CPU의 각종 레지스터 상태를 가리키는 포인터
  * 계정 정보
  * 기억 장치 관리 정보
  * 입출력 정보
  * 부모 프로세스를 가리키는 포인터
  * 자식 프로세스를 가리키는 포인터

## 10. CPU 스케줄링

* 최적의 효과(처리율 향상, 신속한 처리 등)을 보기 위해서는 프로세스의 계획적인 실행 순서가 필요하다.

* 계획적인 실행 순서를 CPU 스케줄링 / 프로세스 스케줄링 이라고 한다.

  ### 10-1. 스케줄러 종류

  * 상위 수준의 스케줄러 : CPU가 아닌 시스템 내의 자원들을 관리하는 수준
  * 중위 수준의 스케줄러 : 어느 프로세스부터 CPU를 사용할 수 있는지를 결정하는 CPU 스케줄러
  * 하위 수준의 스케줄러 : CPU 사용 중에 보류와 디스패치 시기를 결정하는 프로세스 스케줄러를 의미

  ### 10-2. 스케줄링 목적

  * 프로세스 스케줄링은 CPU나 자원을 효과적이며 생산성있게 사용하기 위한 소프트웨어적 계획을 의미
  * 필요한 하드웨어 레지스터를 설정함으로써 프로세스에게 CPU를 할당하고 문맥 교환을 하는 프로세스 관리 기능이다.
  * 모든 프로세스에게 공정하게 배정
  * 단위 시간당 가능한 최대한 많은 양이 처리될 수 있도록 한다.
  * 응답 시간이 신속해야 한다.
  * 같은 종류의 작업은 거의 같은 시간과 비용으로 실행될 수 있어야 한다.
  * 오버헤드를 최소화해야 한다.
  * 시스템 내의 자원이 사용하지 않는 시간이 없도록 유지해야 한다.
  * 응답 시간과 자원의 활용 간 적절한 균형이 유지되도록 해야 한다.
  * 프로세스가 무한정 기다리게 하는 것을 피해야 한다.
  * 프로세스의 상태를 파악하여 우선순위를 부여 하는 것이 좋다.
  * 중요 자원을 차지하고 있는 프로세스에게 우선권을 주어야 한다.
  * 문제로 인해 불안하지 않은 프로세스에 서비스를 많이 제공하도록 한다.
  * 부하가 많은 경우 갑자기 체증이 발생하지 않도록 조절한다.

  ### 10-3. 스케줄링 성능 평가 기준

  * CPU 이용률
  * 처리 능력(Throughput)
  * 대기 시간
  * 응답 시간
  * 반환 시간

## 11. 비선점형 프로세스 스케줄링(Non Preemptive)

* 프로세스가 CPU에 할당되면 권한을 빼앗을 수 없다.

* 일괄 처리 방식에 적당하다.

* 대화형, 시간분할, 실시간 시스템에 부적절하다.

* FIFO, SJF, HRN, 우선순위, 기한부 방식

* 문맥 교환이 적어 오버헤드가 적다.

  ### 11-1. FIFO(First Input First Out, FCFS : First Come First Served)

  * 먼저 입력된 작업을 먼저 처리한다.
  * 가장 대표적인 비선점형 방식
  * 공평하고 구현이 간단하나 평균 반환 시간이 길다.
  * 짧은 작업이나 중요한 작업을 오랫동안 기다리게 할 수 있다.

  ### 11-2. SJF(Shortest Job First, 최단 작업 우선)

  * 작업이 끝나기까지의 실행 시간 추정치가 가장 작은 작업을 먼저 실행 시킨다.
  * 크기가 큰 작업들을 어느 정도는 희생시키면서 짧은 작업들을 우선으로 처리하기 때문에 대기 리스트 안에 있는 작업의 수를 최소화 하면서 평균 반환 시간을 최소화할 수 있다.
  * 긴 작업일지라도 이미 CPU를 점유하고 있다면 뒤로 밀려나지 않고 처리되고 다음 작업들을 대상으로 재정리 한다.
  * 짧은 작업들 때문에 우선순위가 계속 밀려 나면서 긴 작업들은 무한 연기 상태가 발생할 수 있다.
  * 평균 대기 시간을 최소화 한다.
  * 무한 연기 현상을 방지하기 위해 Aging 기법을 사용하여 해결한다.
  * Aging 기법 : 자원이 할당되기를 오랜 시간 동안 기다린 프로세스는 기다린 시간에 비례하는 높은 우선순위를 부여하여 가까운 시간 안에 자원이 할당되도록 하는 기법이다.

  ### 11-3. HRN(Highest Response-ratio Next)

  * 실행 시간 추정과 선점 기능 때문에 스케줄러가 복잡해지고 남은 계산 시간들을 저장해 놓아야 하는 단점을 보안
  * 서비스 시간(실행 시간 추정치)과 대기 시간의 비율을 고려한 스케줄링
  * 대기 리스트에 있는 작업들에게 합리적으로 우선순위를 부여하여 많고, 적은 작업들의 불평등을 해소한 방식으로 SJF의 단점을 보안환 방식
  * 우선 순위 계산 공식을 이용한다.
  * 우선순위 = (대기 시간 + 서비스 시간) / 서비스 시간 (서비스 시간 = 실행(추정) 시간)

  ### 11-4. 우선순위

  * 대기 리스트에 있는 프로세스들에게 작업의 우선순위를 부여하여 CPU를 할당하는 방법
  * 중요한 작업을 먼저 할 수 있다.
  * 기아 현상, 무한 봉쇄 현상이 발생할 수 있다.

  ### 11-5. 기한부(Deadline)

  * 작업이 주어진 특별한 시간이나 만료 시간 안에 완료되도록 하는 방식이다.
  * 프로세스들이 마감 시간 내에 처리되지 않으면 폐기되거나 다시 처음부터 실행해야 한다.
  * 기한부 스케줄링에 필요한 집약적 자원 관리는 많은 오버헤드를 일으킬 수 있다.
  * 동시에 다수의 기한부 작업이 수행되면 스케줄링은 매우 어려워진다.
  * 사용자는 작업에 필요한 자원의 정보를 정확한 정보를 시스템에 제시하여야 한다.
  * 프로세스 양이 늘어나면 오버헤드 측면에서 안정적이지 못하다.

## 12. 선점형 프로세스 스케줄링(Preemptive)

* 프로세스가 CPU에 할당되면 우선순위가 높으면 빼앗을 수 있다.

* 일괄 처리 방식에 부적당하다.

* 대화형, 시간 분할, 실시간 시스템에 적당하다.

* RR, SRT, MFQ

* 문맥 교환이 많아 오버헤드가 많다.

  ### 12-1. RR(Round Robin, 라운드 로빈) 

  * 시분할 시스템을 위해 고안
  * 여러 개의 프로세스가 어느 정도의 시간 할당량이라는 작은 단위 시간이 정의되어 시간 할당량만큼씩 CPU를 사용하는 방법
  * FIFO를 선점형으로 한 방식
  * CPU에게 할당 받은 시간동안 작업을 완료하지 못하면 CPU는 다음 대기 중인 프로세스에게로 사용 권한이 넘어가고 현재 실행 중이던 프로세스는 대기 리스트(Ready List)의 가장 뒤로 배치된다.
  * 할당된 시간 : Time Slice, Quamtum
  * 적절한 응답 시간을 보장해 주는 대화식 사용자에게 효과적이다.
  * 동일한 시간을 사용하는 시분할 시스템에 효과적이다.
  * 시간 할당량이 적은 경우 문맥 교환에 따른 오버헤드가 커진다.
  * 시간 할당량이 너무 작으면 문맥 교환수가 증가한다.
  * 시간 할당량이 너무 작으면 오버헤드가 커지게 된다.
  * 시간 할당량이 너무 작으면 프로세서의 교환에서 시간을 소비하고 실제 사용자들의 연산은 거의 못한다.
  * 시간 할당량이 너무 크면 FIFO와 같은 형태가 된다.
  * 시간 할당량이 너무 크면 CPU를 사용하지 않는 시간이 많아진다.

  ### 12-2. SRT(Shortest Remaining Time)

  * 작업이 끝나기까지 '남아 있는' 실행 시간의 추정치가 가장 작은 프로세스를 먼저 실행한다.
  * 새로 입력되는 작업까지도 포함이다.
  * 남아 있는 프로세스의 실행 추정치가 더 작은 프로세스가 있다면 언제든지 현재 작업 중인 프로세스를 중단하여 더 작은 프로세스에게 CPU를 넘겨주게 되는 방식
  * 서비스 받은 시간을 기록해야 하므로 오버헤드가 늘어난다.
  * 평균 대기 시간과 대기 시간의 분산도 크다.
  * 실행 시간을 추적해야 하므로 오버헤드가 증가한다.
  * 임계치(Threshold Value)를 사용한다.
  * Threshold Value : CPU를 사용 중인 프로세스가 거의 막바지에 이르렀을 때 남아 잇는 시간보다 조금 작은 프로세스가 입력된다면 CPU 사용 권한을 넘겨줘야 할 것이다. 하지만 이럴 경우 문맥 교환 횟수나 전체 정황으로 보았을 때 현재 작업 중인 프로세스를 모두 마치고 조금 작은 프로세스를 다음에 처리하는 것이 더 효율적일 것이다. 이 수치 값이 Threshold Value(임계치)다.

  ### 12-3. 다단계 피드백 큐(MFQ : Multi level Feedback Queue)

  ![img](https://mblogthumb-phinf.pstatic.net/20150602_285/jvioonpe_1433213349396GkDaS_JPEG/%B4%D9%B4%DC%B0%E8%C7%C7%B5%E5%B9%E9%C5%A5.jpg?type=w2)

  * 맨 위에 있는 큐가 가장 우선순위가 높고 시간 할당량도 적다.
  * 아래로 갈수록 우선순위가 낮고 시간 할당량은 크게 배치된다.
  * 각 큐는 자신보다 낮은 단계의 대기 리스트들에서 절대적인 우선순위를 갖게 된다.
  * A 대기 리스트에서 작업하던 프로세스가 정해진 시간 할당량을 사용하고 남게 되면 중단 시키고 나머지 작업에 대해서는 B 대기 리스트로 이동하고 다음 프로세스에게 CPU를 할당한다. 나머지도 대기 리스트도 마찬가지다.
  * 가장 낮은 대기 리스트는 맨 마지막이기 때문에 라운드 로빈 스케줄링으로 운영한다.
  * B 대기 리스트에 있는 프로세스들은 A 대기 리스트에 프로세스가 존재하지 않아야만 CPU를 사용할 수 있다.
  * 만약 B 대기 리스트에 있는 프로세스가 CPU를 사용 중일 때 A 대기 리스트에 프로세스가 입력되면 바로 중단하고 A 대기 리스트에 있는 프로세스에 CPU 사용 권한을 넘겨주어야 한다.
  * 짧은 작업이나 CPU를 적게 사용하는 입출력 작업들은 최상위 큐에서 빨리 처리하자는 것이다. 
  * 짧은 작업이나 입출력 위주의 작업에 우선권을 부여하기 위해 개발된 방식으로 적응 기법의 개념을 적용한다.
  * 큐마다 시간 할당량(Quantum)이 존재하며 낮은 큐일수록 시간 할당량은 커진다.
  * 각각의 큐들은 종속적으로 연결되어 있다.

  ### 12-4. 다단계 큐(MQ : Multi level Queue)

  ![img](http://postfiles4.naver.net/20160424_179/jk130694_1461472911951iY2So_PNG/1.png?type=w2)

  * 맨 위의 큐가 가장 우선순위가 높고, 아래로 갈수록 우선순위가 늦게 구성된다.
  * 우선순위가 가장 낮은 작업들은 대부분 응답 속도가 빠르지 않아도 되는 일괄 처리형 큐를 사용한다.
  * 각 큐들은 자신보다 낮은 단계의 큐에서 절대적인 우선순위를 갖게 된다.
  * 우선순위가 가장 높은 대기 리스트에 존재하느 프로세스는 어떠한 경우라도 프로세스를 빼앗기지 않는 비선점형이다.
  * 나머지 대기 리스트에 존재하는 프로세스들은 우선순위가 높은 큐에 프로세스가 입력되면 CPU를 빼앗기게 되므로 선점형이 된다.
  * 다단계 큐는 선점과 비선점을 결합한 스케줄링이다.
  * 대기 리스트를 특성별로 여러 개 가진다.
  * 대기 리스트마다 독립적인 스케줄링을 가진다.
  * 대기 리스트 간에 프로세스가 이동이 안 된다.

## 13. 임계 구역(Critical Section, 위험 지구)

## 14. 상호 배제

## 15. 세마포어

## 16. 모니터

## 17. 교착상태

## 18. 인터리빙(Interleaving)

* 주기억 장치의 엑세스 속도를 빠르게 하기 위한 기술이다.
* 기억 장치의 연속된 위치를 서로 다른 뱅크로 구성하여 하나의 주소로 여러 개의 위치에 해당하는 기억 장치를 접근 할 수 있도록 하는 방법이다.
* 하나의 장치가 독립적인 기능을 하는 다른 장치의 상태를 검사할 수 있도록 허가하는 기법을 폴링(Polling)이라고 한다.

## 19. DMA(Direct Memory Access)

* CPU를 거치지 않고 직접 주기억 장치와 주변 장치 사이에서 데이터를 주고받는 입출력 제어기이다.
* 입출력에 대한 CPU의 부담을 줄이는 동시에 엑세스 속도를 향상시킨다.
* 사이클 스틸링(Cycle Stealing) 기법을 사용한다.
* Cycle Stealing : 중앙 처리 장치와 입출력 장치가 동시에 주기억 장치에 접근하려는 경우, 입출력 장치에 우선순위를 부여하는 것으로, 적응 양의 사이클을 필요로 하는 채널에 우선순위를 높여 주면 입출력 장비의 효율이 높아진다.

## 20. 주 기억 장치 다중 프로그래밍

## 21. 가상 기억 장치(보조 기억 장치) 다중 프로그래밍

## 22. 가상 기억 장치 주요 기술

## 23. 반입(Fetch) 전략

### 23-1. 요구(Demand) 반입

## 24. 배치 전략

## 25. 교체(재배치 전략)

## 26. 디스크

## 27. 디스크 스케줄링

## 28. 파일의 구조

* 파일 시스템이 사용하는 파일 기록 방식

  ### 28-1. 순차 접근 파일(Sequential Access File)

  * 입력되는 데이터의 논리적인 순서에 따라 물리적으로 연속적인 위치에 기록하는 파일 방식
  * 저장 매체의 효율이 매우 높다.
  * 물리적으로 연속적인 저장이 되기 때문에 Access 시간이 가장 빠르다.
  * 특정한 데이터를 검색하는데 비교 횟수가 많아지므로 Seek(검색) 시간이 느리다.
  * 저장 정보를 따로 구성하지 않아도 되므로 공간의 낭비가 없다.
  * 구현이 쉽기 때문에 어떤 매체라도 쉽게 사용할 수 있다.
  * 일괄 처리에 접합하다.
  * 테이프를 모형화한 것이다.

  ### 28-2. 직접 접근 파일(Direct Access File)

  * 데이터 내의 키 필드(Key Field)를 해싱 사상 함수에 의해 물리적인 주소로 변환하여 데이터를 기록하거나 검색하는 방식의 파일이다.
  * DASD(Direct Access Storage Device)의 물리적 주소를 통하여 직접 액세스 된다.
  * 특정 레코드를 검색하기 위하여 Key와 보조 기억 장치 사이의 물리적인 주소로 변환할 수 있는 사상 함수(Mapping Function)가 필요하다.
  * 해싱 사상 함수를 사용하므로 검색 속도가 가장 빠르다.
  * 한번 파일을 개방하면 읽거나 쓰기를 자유롭게 할 수 있다.
  * 어떤 레코드라도 평균 접근 시간 내에 접근할 수 있다.
  * 키 변환법에 따라 공간의 낭비를 가져올 수 있다.
  * 디스크 기억 장치에 많이 사용된다.

  ### 28-3-1. 색인 순차 접근 파일(Indexed Sequential Access File)

  * 순차 파일과 직접 파일에서 지원하는 편성 방법이 결합된 형태로 순차 처리와 직접 처리가 모두 가능하다.
  * 디스크 기억 장치에 많이 이용된다.
  * 각 레코드는 레코드 키 값에 따라 논리적으로 배열된다.
  * 시스템은 각 레코드의 실제 주소가 저장된 인덱스를 관리한다.
  * 융통성이 매우 뛰어나다.
  * 레코드를 추가 및 삽입하는 경우 파일 전체를 복사할 필요가 없다.
  * 실제 데이터 처리 외에 인덱스를 처리하는 추가적인 시간이 소모되므로 파일 처리 속도가 느리다.
  * 인덱스를 저장하기 위한 공간과 오버플로 처리를 위한 별도의 공간이 필요하므로 기억 공간의 낭비가 있다.
  * 파일을 구성하는 블록의 번호는 절대 블록 번호여야 사용자가 자신의 파일이 아닌 부분에 접근하는 것을 방지할 수 있다.
  * 삽입, 삭제가 많아지면 파일에 대한 재편성이 이루어져야 한다.

  ### 28-3-2. 3단계 색인 구역(Index Area)

  * Master Index : Cylinder Index 구역의 인덱스
  * Cylinder Index : Track Index 구역의 인덱스
  * Track Index : 기본 데이터 구역의 인덱스

  ### 28-4. 분할 파일(Partition File)

  * 하나의 파일을 여러 개의 파일로 재구성한 파일이다.
  * 분할된 파일은 여러 개의 순차 서브 파일로 구성된 파일이다.
  * 파일의 크기가 큰 경우에 사용한다.
  * 하드 디스크를 플로피 디스크에 저장할 때 사용한다.

## 29. 파일의 디스크 공간 할당

* 파일의 데이터를 디스크에 물리적으로 저장하고 삭제하는 방법을 말한다.

  ### 29-1. 연속 블록 할당(Contiguous Block Allocation)

  * 데이터를 물리적, 연속적으로 저장한다.
  * 데이터를 저장할 크기를 미리 지정해야 한다.
  * 파일마다 크기가 다르고 추가, 삭제가 빈번히 발생할 경우에 단편화 현상이 많이 발생한다.
  * 디스크 활용을 최대화하기 위한 통합(Coalecing), 집약(Compaction, garbage Collection)이 필요하다.
  * 파일의 크기보다 큰 연속 공간이 없을경우에는 파일을 생성할 수 없다.
  * 가상 기억 장치를 응용하여 사용할 수 없다.
  * 용적률이 줄어든다.
  * 액세스 시간이 감소한다.
  * 디렉터리 구현이 쉽다.

  ### 29-2. 불연속 블록 할당(Link Block Allocation)

  * 디스크 공간을 일정한 길이를 갖는 단위(섹터, 블록)로 나누어 할당하는 기법이다.
  * 분할된 영역은 독립적으로 취급되며 파일의 데이터들은 불할된 영역에 순차적, 분산적으로 저장할 수 있는 방법이다.
  * 분할 저장된 파일의 각 데이터들은 파일 Open시에 연결된 정보를 이용해 사용된다.
  * 실제 데이터를 저장하는 공간 외에 분할된 정보와 파일의 연결된 데이터 정보를 저정해야 하는 영역이 필요하므로 부가적인 저장 공간이 연속 블록 할당에 비해 많이 사용된다.
  * 파일의 크기에 해당되는 디스크 공간을 미리 지정해 주지 않아도 된다.
  * 단편화를 줄일 수 있다.
  * 디스크 압축(집약)이 불필요하다.
  * 파일의 크기보다 큰 연속 공간이 없을 경우라도 파일을 생성할 수 있다.
  * 가상 기억 장치를 응용하여 사용할 수 있다.
  * 용적률이 좋아진다.
  * 액세스 시간이 증가한다.
  * 디렉터리 구현이 어렵다.
  * 섹터 단위형 : 디스크 섹터 단위로 파일의 데이터가 분산되어 저장된다.
    * 각 섹터는 연결 리스트 구조 형태로 연결된다.
    * 파일의 크기가 커지면 비어 있는 섹터를 사용하고 작아지면 사용하지 않은 섹터를 반납한다.
  * 블록 단위형
    * 블록 체인 기법 : 여러 개의 섹터를 묶은 블록을 체인처럼 연결한 방법
    * 인덱스 블록 체인 기법 : 인덱스에 블록의 주소를 링크시켜 사용한다. (Unix)
    * 블록 단위 파일 사상 기법 : 파일 정보의 해당 블록을 사상시켜 연결하여 사용한다. (MS-DOS, MS-Windows)

## 30. 디렉터리

* 파일 시스템 내부에 있는 기능으로 디스크 내에 존재하는 많은 파일을 쉽게 사용할 수 있도록 조직화된 기법이다.

  ### 30-1. 1단계 디렉터리

  ![img](http://cfile9.uf.tistory.com/image/2438763A55A73E203358D6)

  * 가장 간단한 디렉터리이다.
  * 디렉터리 시스템에 보관된 모든 파일의 정보를 포함해야 한다.
  * 파일이 같은 디렉터리 내에 있어야 하므로 유일한 파일명으로 작성해야 한다.
  * 파일명의 길이를 제한한다.

  ### 30-2. 2단계 디렉터리

  ![img](http://cfile26.uf.tistory.com/image/27475F4655A73E212931CE)

  * 중앙에 마스터 디렉터리가 존재하고 그 아래 사용자 디렉터리가 있는 구조다.
  * 다른 사용자와의 파일 공유가 어렵다.(다른 사용자의 디렉터리 안에 파일들을 검색할 수 없으므로 공유가 어렵다.)
  * 파일명의 길이가 길어 사용하기 매우 어렵다.(파일명뿐만 아니라 사용자 디렉터리명을 같이 지정해야 한다.)
  * 2단계 이상으로 깊어지면 트리 구조 디렉터리가 된다.

  ### 30-3. 트리 구조 디렉터리

  ![img](http://cfile30.uf.tistory.com/image/261D2C3355A73E212F6A08)

  * 하나의 루트 디렉터리와 여러 개의 부 디렉터리로 구성된다.
  * 부 디렉터리는 그 하위로 또 다른 디렉터리를 구성할 수 있다.
  * 각 디렉터리의 생성과 파괴가 용이하다.
  * 동일한 이름의 여러 디렉터리 생성이 가능하다.
  * Unix, MS-DOS, MS-Windows에서 사용한다.

  ### 30-4. 비순환(주기) 그래프 디렉터리

  ![img](http://cfile27.uf.tistory.com/image/2254493C55A73E2211B451)

  * 트리 구조와 유사하다.
  * 사이클을 허용하지 않는다.
  * 하나의 파일이나 디렉터리를 상위 드렉터리에 공용할 수 있다.
  * 링크 수만큼 파일을 공유하고 있으며 링크 수가 0이면 완전히 제거할 수 있다.
  * 하나의 파일을 여러 사용자가 공유하기 때문에 삭제 시 문제점이 많이 발생한다.
  * 융통성이 있으며 기억 공간을 절약할 수 있으나 복잡하다.
  * 공용된 파일이나 디렉터리는 물리적으로 한 개만 존재한다.
  * 하나의 파일이 다수의 이름으로 존재할 수 있다.
  * 공유하고 있는 파일 제거 시 **Dangling Pointer**가 발생할 수 있다.
  * Unix에서 사용한다.

  ### 30-5. 일반 그래프 디렉터리

  ![img](http://cfile5.uf.tistory.com/image/2175C13B55A73E232A5A06)

  * 그래프 탐색 알고리즘이 간단하다.
  * 사이클을 인정하므로 파일 접근이 용이하다.
  * 하나의 파일이나 디렉터리를 상위 디렉터리에 공용할 수 있다.
  * 상위 파일이나 디렉터리를 자신의 파일이나 하위 디렉터리로 구성할 수 있다.
  * 파일을 제거하기 위한 **Garbage-Collection(자투리 제거기)을 위한 참조 계수기**가 필요하다.

## 31. 자원 보호 기법

* 자원 보호 기법은 컴퓨터 시스템에서 보호되어야 할 모든 대상의 접근 목록을 두어 접근 가능한 사용자와 가능한 동작을 기록한 후, 이를 근거로 접근을 허용하다는 기법

  ### 31-1. Access Control Matrix(접근 제어 행렬)

  ![img](https://2.bp.blogspot.com/-4xCWhAzMeUg/V0ayYRpqmjI/AAAAAAAAAKg/6ZnkVCAHktsjkKice4cjOZav-iq33BVQwCLcB/s1600/%25EC%25A0%2591%25EA%25B7%25BC.PNG)

  * 객체의 사용 권한을 모든 사용자 리스트와 함께 표시하는 행렬
  * 임의의 사용자가 허용되지 않은 자원에 접근하지 못하도록 한다.
  * 사용자가 많게 되면 공간 낭비가 많아 호율이 떨어진다.
  * 시스템 관리자는 모든 자원을 제어할 수 있는 권한을 갖고 있다.

  ### 31-2. Access Control List(접근 제어 리스트)

  ![img](https://2.bp.blogspot.com/-H9BCx1Pyhjc/V0ay4NYSSuI/AAAAAAAAAKo/5RzdfTdepCMosyrwkAc5F-Ah9JlGEGPSACLcB/s1600/%25EC%25A0%2591%25EA%25B7%25BC%2B%25EC%25A0%259C%25EC%2596%25B4.PNG)

  * 객체와 그 객체에 허용된 조작 리스트
  * 영역과 결합되어 있으나 사용자에 의해 간접적으로 엑세스되는 기법
  * 접근 제어 행렬에서 허용되지 않은 사용자는 제외한다.
  * 보호하려는 대상에 영역별로 접근 권한을 구성하여 사용한다.
  * 접근 행렬의 열을 하나의 리스트로 묶어 놓는 것이다.
  * 권한이 없는 셀을 위한 메모리를 낭비할 필요가 없어지므로 효율적으로 사용할 수 있다.

  ### 31-3. Capability List(자격 리스트)

  ![img](https://1.bp.blogspot.com/-_3wJJ-16NgM/V0ay7WCi_mI/AAAAAAAAAKs/CFH6q7q3i5wrn7ckWoAuqb4GbvajtmtKACLcB/s1600/%25EA%25B6%258C%25ED%2595%259C.PNG)

  * 사용자 개개인에 허용된 조작 리스트로 사용자가 시스템에 접근하면 사용자의 권한을 파악하게 된다.
  * 접근 제어 행렬에서 수평으로 있는 각 행만을 따온 것으로서 영역에 대한 권한은 객체와 그 객체에 허용된 연산자로 구성되어 있다.

## 32. 비밀키와 공개키

* 암호화 기법으로 암호화 되기 전을 플레인 텍스트(Plain Text), 암호화 되고 난 후를 사이퍼 텍스트(Cipher Text)

  ### 32-1. 비밀키, 공통키, 대칭형 암호화 알고리즘(Private Key System)  

  * 암호화 키와 복호화 키는 같은 키이다.
  * 해독키의 비밀성은 보장되어야 한다.
  * 정보를 교환하고 있는 사람들끼리만 비밀키를 사용해야 하므로 키 분배가 어렵다.
  * 디지털 서명이 어렵다.
  * 평문을 암호화하는데 가장 많이 사용한다.
  * 대칭키, 관용키, 단일키, 비밀키, 공통키
  * DES, IDEA, RC2 등으로 복호화 한다.
  * 대체 기법 : 어떤 알고리즘이나 추측에 의해서 알아맞힐 수 없는 특수한 암호키를 가지고 데이터를 암호화했다가 자료 이용 시 같은 암호키를 이용하여 해독하는 기법
  * DES(Data Encryption Standard) : 미국 상무국 표준 협의에서 공모하여 사용하고 있는 암호화 기법으로, 56비트의 암호/복호키를 이용하여 64비트의 평문을 암호화 또는 복호화하는 기법
  * 계산속도가 빠르다
  *  많은 암호화 통신에서는 비밀 키 암호를 사용하여 대칭 키 암호의 공통키를 공유하고, 그 키를 기반으로 실제 통신을 암호화하는 구조를 사용한다.

  ### 32-2. 공개키, 비대칭형 암호화 알고리즘

  * 암호화 키와 복호화 키는 다른 키를 사용한다.
  * 공개키(암호화 키)는 공개되지만, 비밀키(복호화 키)는 보호되어야 한다.
  * 키 분배는 공통 키 분배보다 비교적 간단하다.
  * 디지털 서명에 적당하다.
  * 암호화 과정이 복잡하여 속도가 느리다.
  * 비대칭키, 공용키
  * RSA, PGP 등 암호 방식이 있다.
  * RSA : 데이터를 암호문으로 변환할 때 암호키와 암호문을 평문으로 변환시킬 때 복호키가 서로 다르며 암호화하는 암호키는 공개하고 복호키는 비밀로 해 데이터의 송수신 시 보안을 유지하는 방법


  * 공개 키와 비밀 키가 존재, 공개 키는 누구나 알 수 있지만 그에 대응하는 비밀 키는 소유자만 알 수 있어야 한다. 
  * 공개 키 암호 : 특정한 비밀 키를 가지고 있는 사용자만 내용을 열어볼 수 있다.
  * 공개 키 서명 : 특정한 비밀 키로 만들었다는 것을 누구나 확인 할 수 있다.
  * 개인키로 암호화한 정보는 그 쌍이 되는 공개키로만 복호화 가능하고, 반대로 공개키로 암호화 한 정보는 그 쌍이 되는 개인키로만 복호화가 가능하다.

## 33. MIMD(Multiple Instruction Multiple Data)

* 다중 처리기 컴퓨터

* 한번에 여러 개의 명령어를 처리한다.

* 여러 명의 사용자가 여러 개의 CPU를 사용한다.

  ### 33-1. 다중 처리기(Multi processor)

  * 여러 개의 CPU가 하나의 메모리를 공유하는 형태
  * CPU 끼리의 결합력이 강하다.
  * 병렬 처리에 적합한 컴퓨터 시스템 구조이다.
  * 전송 지연이 짧고 데이터 처리율이 높다.
  * 프로세스 간 통신은 공유 메모리를 통해 이루어진다.
  * 공유 메모리를 차지하려는 프로세스 간의 경쟁이 발생한다.
  * 기억 장소가 하나이므로 운영체제도 종속적으로 사용된다.
  * 모든 CPU는 하나의 운영체제에서 통제되는 대칭적인 구조이다.

  ### 33-2. 다중 컴퓨터(Multi computer)  

  * 여러개의 CPU가 자신만의 독립적인 메모리를 사용하는 형태
  * CPU끼리 결합력이 약하다.
  * 분산 처리에 적합한 컴퓨터 구조이다.
  * 전송 지연이 길고 데이터 처리율이 낮다.
  * 프로세스간 통신은 통신망에 메시지(소켓 : Socket) 전달로 통신할 수 있다.
  * 구성 요소(컴퓨터, 주변 장치 등)의 추가 또는 삭제가 용이하다.
  * 기억 장소가 CPU와 독립적으로 사용되므로 운영체제도 독립적으로 사용된다.
  * 각 시스템은 자신만의 운영체제를 갖는 분리 수행 구조이다.

## 34. 분산 운영체제

## 35. 투명성

## 36. 스레드

----

**모든 내용의 권리는 2018 정보처리기사(영진 닷컴 출판사) 에 있습니다.** 